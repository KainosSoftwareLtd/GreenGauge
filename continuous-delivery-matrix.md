| Section                | Description |                                                                                                                                                                                                                                                 Main areas                                                                                                                                                                                                                                                  |                                                                                                                                                                                            1 Point                                                                                                                                                                                             |                                                                                                                                                                                                                   3 Points                                                                                                                                                                                                                   |                                                                                                      5 Points                                                                                                      |
|------------------------|:-----------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| Build                  | Reduce the carbon footprint by optimizing energy consumption in your build processes. For example, in optimising the development environments allowing developers to catch/find problems sooner on their local machines, it means less wasted resources elsewhere in the lifecycle. | **Static Analysis**: There are now several mechanisms that can now measure carbon awareness in code - are you using such tools to identify improvements?<br/><br/>**Peer reviews**: Does your process interrogate the efficiency of the solution or does it just focus on the fact that it works? Do you have a 'green code review' guidance?<br/><br/>**CI/CD**: Have you optimised your build infrastructure to reduce its carbon footprint by reducing waste and improving efficiency? | **Static Analysis**: We do static analysis, but we don't apply a green software lens to this.<br/><br/>**Peer Reviews**: Any changes we make require an approval where another member of the team has to review/approve changes.<br/><br/>**CI/CD**: We have dedicated CI/CD infrastructure with always-on build-agents. | **Static Analysis**: We do static analysis and have enabled the green software scanners. There are lots of false positives, but we're working through this to find genuine improvements.<br/><br/>**Peer Reviews**: Any changes we make require an approval from a more senior member of the team with green software efficiency being prioritised.<br/><br/>**CI/CD**: We have dedicated CI/CD build infrastructure but build agents only get provisioned when there is work to do. | **Static Analysis**: We do static analysis and have enabled the green software scanners. We've tuned our implementation of this to improve the signal-to-noise ratio.<br/><br/>**Peer Reviews**: As well as manual reviews and approvals, we have integrated automated tools to give us feedback on the efficiency of the code.<br/><br/>**CI/CD**: We make use of a SaaS hosted CI/CD solution where local build agents only get provisioned when there is work to do. |
| Deployment and Release | When you design your system with more independent and flexible components, you can make smaller changes to each part. This helps you to improve your deployment process and reduce the environmental and hardware costs. Also, when you have smaller changes to make, you can deliver better services to your users faster and safer, because you have less risk of breaking something. | **Reduce waste**: Two of the most important areas of digital hygiene that can have a huge impact are<ol><li>Turning systems off which you aren't using</li><li>removing systems, or parts of systems, that you no longer require</li</ol><br/><br/>**Automation**: You use automation to make waste reduction easier e.g. turning off an environment overnight knowing you can quickly redeploy when it's required.<br/><br/>**Modularity**: When you have smaller parts to change, you can change them more easily. If your system is made of flexible and independent components, you can improve your green software practices without worrying about affecting other parts or causing failures. |**Reduce waste**: Our environments tend to be long lived whether they are being actively used or not. Given how environments bloat over time, we will almost certainly find provisioned resources which aren't really needed.<br/><br/>**Automation**: We use little automation which means deployments can take a little time.<br/><br/>**Modularity**: We release everything relating to our service at the same time; so managing dependencies is not a problem. Our releases tend to be less frequent as a result of having to deploy everything. | **Reduce waste**: We use concepts such as infrastructure as code to ensure unused resources get cleaned up over-time though generally speaking, our environments tend to be long-lived.<br/><br/>**Automation**: We use infrastructure as code automation in combination with configuration management to apply changes. Applying new code changes tends to be fully-automated.<br/><br/>**Modularity**: Many of our components are independent of each other so we can release these independently whenever we wish to make a change. We can release these components as often as we like though engaging with third-parties does slow this down. | **Reduce waste**: Our environments tend to be short-lived and we provision them on-demand using Infrastructure as code.<br/><br/>**Automation**: We use infrastructure as code automation in combination with configuration management to rapidly build new environments and apply code-changes in an end-to-end manner.<br/><br/>**Modularity**: All of our components can be independently deployed and we utilise approaches like API versioning and we work with third-parties to streamline our integration when necessary. |
| Operations             | Feedback from ongoing operations and monitoring data can be used to identify trends to continuously improve and optimise your service. For example, understanding that a trends follows a specific cycle, for example a season, or that most of your users access the service from a specific region may impact some of the decisions you make around ongoing operations. | **Patching**: Software is regularly updated to make performance improvements. You regularly patch your software to ensure you are running the latest versions. This gives you the benefit of those improvements.<br/><br/>**Feature toggling**: Being able to dynamically control/toggle features within your application provides opportunities to optimise for certain scenarios. | **Patching**: We apply urgent security updates when they are available.<br/><br/>**Feature Toggling**: We don't make use of this. Turning something off would necessitate a code change. | **Patching**: We apply security updates when they are available and consider patching/upgrading other components when new features touch those components.<br/><br/>**Feature Toggling**: We can toggle certain software features on or off to reduce the environmental impact of our software. | **Patching**: We regularly patch and upgrade all software underpinning the service.<br/><br/>**Feature Toggling**: We automatically toggle certain software features on or off to reduce the environmental impact of our software based on external parameters. |
| Testing                | Testing is an integral part of how we validate the quality of the software solutions we build, but do you test in a way that aligns with green software practices, minimising the resources required to prove whether the code works? For example, do you always run every integration/BDD test relating to the component or just the subset of tests relating to the area where you have made a change? | **Change aware**: Testing only what has changed means you don't waste resources testing what hasn't changed.<br/><br/>**NFR testing**: You should keep checking your NFRs while making your service more efficient. If you change to a new and better service level, how do we make sure our performance is still good enough?<br/><br/>**Benchmarking**: Sometimes tests are binary pass/fail and in other cases adding tolerances is more appropriate. Do you fail the build when any of your tests or static analysis for sustainability fail? Perhaps one issue is not enough to fail the build but what would you consider to be an acceptable level of green debt issues?<br/><br/>**Production Datasets**: You might get unexpected results if you don’t test with production data. How fast is your database search or your result calculation indexing? You might not notice big performance issues with a small dataset. | **Change Aware**: We execute all tests on each code commit.<br/><br/>**NFR Testing**: Around major releases we do significant NFR testing e.g. system testing. But on each code change in-between, we don't really apply any.<br/><br/>**Benchmarking**: A test either passes or breaks the build.<br/><br/>**Production Datasets**: We don't regularly test with production datasets that replicate either the scale or variance of the data. | **Change Aware**: We execute all tests relating only to the component which has been changed and its integrations.<br/><br/>**NFR Testing**: We regularly (at least once a sprint) undertake some form of scheduled NFR testing to review system performance and to test component resiliency.<br/><br/>**Benchmarking**: We have some rudimentary tolerance checks built in to break the build under certain conditions e.g. if static analysis has found more than 5 high priority green software actions that require fixing.<br/><br/>**Production Datasets**: We have some environments where we regularly test with production datasets to ensure that performance/behaviour remains consistent with test data. | **Change Aware**: We execute all tests relating only to the feature which has been added/changed and its integrations.<br/><br/>**NFR Testing**: On each code change we are able to execute NFR testing relating to the feature or component that has been changed.<br/><br/>**Benchmarking**: We integrate the output of NFR testing to determine failure tolerances for new builds e.g. if performance degrades.<br/><br/>**Production Datasets**: We have on-demand environments where we can regularly test with production datasets to simulate production size, scale and variance. |