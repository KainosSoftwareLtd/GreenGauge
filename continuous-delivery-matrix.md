# Continuous delivery maturity

This pillar of the maturity model covers ....

* [Build](#Build)
* [Deployment and release](#Deployment-and-release)
* [Operations](#Operations)
* [Testing](#Testing)

### Build 
Reduce the carbon footprint by optimizing energy consumption in your build processes. For example, in optimising the development environments allowing developers to catch/find problems sooner on their local machines, it means less wasted resources elsewhere in the lifecycle.  

| Measure | Description | Score: 1 | Score: 3 | Score: 5 |
| --- | --- | --- | --- | --- |
| **Static Analysis** | There are now several mechanisms that can now measure carbon awareness in code - are you using such tools to identify improvements?| We do static analysis, but we don't apply a green software lens to this. | We do static analysis and have enabled the green software scanners. There are lots of false positives, but we're working through this to find genuine improvements.| We do static analysis and have enabled the green software scanners. We've tuned our implementation of this to improve the signal-to-noise ratio. |
| **CI/CD** | Have you optimised your build infrastructure to reduce its carbon footprint by reducing waste and improving efficiency? | We have dedicated CI/CD infrastructure with always-on build-agents. | We have dedicated CI/CD build infrastructure but build agents only get provisioned when there is work to do. | We make use of a SaaS hosted CI/CD solution where local build agents only get provisioned when there is work to do. |
| **Peer reviews** | Does your process interrogate the efficiency of the solution or does it just focus on the fact that it works? Do you have a 'green code review' guidance? | Any changes we make require an approval where another member of the team has to review/approve changes. | Any changes we make require an approval from a more senior member of the team with green software efficiency being prioritised. | As well as manual reviews and approvals, we have integrated automated tools to give us feedback on the efficiency of the code. |


### Deployment and release 
When you design your system with more independent and flexible components, you can make smaller changes to each part. This helps you to improve your deployment process and reduce the environmental and hardware costs. Also, when you have smaller changes to make, you can deliver better services to your users faster and safer, because you have less risk of breaking something.  

| Measure | Description | Score: 1 | Score: 3 | Score: 5 |
| --- | --- | --- | --- | --- |
| **Reduce waste** | Two of the most important areas of digital hygiene that can have a huge impact are<ol><li>Turning systems off which you aren't using</li><li>removing systems, or parts of systems, that you no longer require</li</ol> | Our environments tend to be long lived whether they are being actively used or not. Given how environments bloat over time, we will almost certainly find provisioned resources which aren't really needed. | We use concepts such as infrastructure as code to ensure unused resources get cleaned up over-time though generally speaking, our environments tend to be long-lived, but production sized environments are limited. | Our environments tend to be short-lived and we provision them on-demand using Infrastructure as code, scaling out to production sized evironments as required with automatic clean up processes in place to remove after use. |
| **Automation** | You use automation to make waste reduction easier e.g. turning off an environment overnight knowing you can quickly redeploy when it's required. | We use little automation which means deployments can take a little time. | We use infrastructure as code automation in combination with configuration management to apply changes. Applying new code changes tends to be fully-automated. |  We use infrastructure as code automation in combination with configuration management to rapidly build new environments and apply code-changes in an end-to-end manner. |
| **Modularity** | When you have smaller parts to change, you can change them more easily. If your system is made of flexible and independent components, you can improve your green software practices without worrying about affecting other parts or causing failures. | We release everything relating to our service at the same time; so managing dependencies is not a problem. Our releases tend to be less frequent as a result of having to deploy everything. | Many of our components are independent of each other so we can release these independently whenever we wish to make a change. We can release these components as often as we like though engaging with third-parties does slow this down. | All of our components can be independently deployed and we utilise approaches like API versioning and we work with third-parties to streamline our integration when necessary. |

### Operations
Feedback from ongoing operations and monitoring data can be used to identify trends to continuously improve and optimise your service. For example, understanding that a trends follows a specific cycle, for example a season, or that most of your users access the service from a specific region may impact some of the decisions you make around ongoing operations.  

| Measure | Description | Score: 1 | Score: 3 | Score: 5 |
| --- | --- | --- | --- | --- |
| **Patching** | Software is regularly updated to make performance improvements. You regularly patch your software to ensure you are running the latest versions. This gives you the benefit of those improvements. | We apply urgent security updates when they are available. | We apply security updates when they are available and consider patching/upgrading other components when new features touch those components. | We regularly patch and upgrade all software underpinning the service. |
| **Feature toggling** | Being able to dynamically control/toggle features within your application provides opportunities to optimise for certain scenarios. | We don't make use of this. Turning something off would necessitate a code change. | We can toggle certain software features on or off to reduce the environmental impact of our software. | We automatically toggle certain software features on or off to reduce the environmental impact of our software based on external parameters. |

### Testing
Testing is an integral part of how we validate the quality of the software solutions we build, but do you test in a way that aligns with green software practices, minimising the resources required to prove whether the code works? For example, do you always run every integration/BDD test relating to the component or just the subset of tests relating to the area where you have made a change?  

| Measure | Description | Score: 1 | Score: 3 | Score: 5 |
| --- | --- | --- | --- | --- |
| **Change aware** | Testing only what has changed means you don't waste resources testing what hasn't changed. | We execute all tests on each code commit. | We execute all tests relating only to the component which has been changed and its integrations.| We execute all tests relating only to the feature which has been added/changed and its integrations. |
| **NFR testing** | You should keep checking your NFRs while making your service more efficient. If you change to a new and better service level, how do we make sure our performance is still good enough? | Around major releases we do significant NFR testing e.g. system testing. But on each code change in-between, we don't really apply any. | We regularly (at least once a sprint) undertake some form of scheduled NFR testing to review system performance and to test component resiliency. | On each code change we are able to execute NFR testing relating to the feature or component that has been changed.|
| **Benchmarking** | Sometimes tests are binary pass/fail and in other cases adding tolerances is more appropriate. Do you fail the build when any of your tests or static analysis for sustainability fail? Perhaps one issue is not enough to fail the build but what would you consider to be an acceptable level of green debt issues? | A test either passes or breaks the build. | We have some rudimentary tolerance checks built in to break the build under certain conditions e.g. if static analysis has found more than 5 high priority green software actions that require fixing. | We integrate the output of NFR testing to determine failure tolerances for new builds e.g. if performance degrades. |
| **Production Datasets** | You might get unexpected results if you donâ€™t test with production data. How fast is your database search or your result calculation indexing? You might not notice big performance issues with a small dataset. | We don't regularly test with production datasets that replicate either the scale or variance of the data. | We have some environments where we regularly test with production datasets to ensure that performance/behaviour remains consistent with test data. | We have on-demand environments where we can regularly test with production datasets to simulate production size, scale and variance. |
